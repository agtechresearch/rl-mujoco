{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stable baseline3 에 훈련 결과를 차트로 뽑아주는 기능이 있는지 살펴보고\n",
    "-> wandb callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 3, 4, 1, 0, 4, 2, 2, 1, 2, 3, 2, 1, 1, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stable-baselines3.readthedocs.io/en/master/guide/algos.html\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "size = 4\n",
    "spaces.MultiDiscrete([size+1] * (size**2)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0]\n",
      "[0 0 0 0]\n",
      "[0 0 0 0]\n",
      "[0 0 0 0]\n",
      "\n",
      "[0 0 0 0]\n",
      "[0 0 0 0]\n",
      "[0 0 0 4]\n",
      "[0 0 0 0]\n",
      "\n",
      "[0 3 2 1]\n",
      "[4 2 3 0]\n",
      "[3 1 0 4]\n",
      "[2 4 1 3]\n",
      "\n",
      "[0 3 4 1]\n",
      "[1 2 3 0]\n",
      "[3 1 0 4]\n",
      "[2 4 1 3]\n",
      "\n",
      "[0 3 4 1]\n",
      "[4 2 3 0]\n",
      "[3 1 2 4]\n",
      "[2 4 1 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SudokuEnv(gym.Env):\n",
    "    def __init__(self, size=4):\n",
    "        self.size = size\n",
    "        self.half_size = size // 2\n",
    "        self.action_space = spaces.Discrete(size**3)\n",
    "        self.observation_space = spaces.MultiDiscrete([size+1] * (size**2))  # 4x4 Sudoku 게임판을 1차원 배열로 표현\n",
    "        self.actions = np.array([\n",
    "            [[(x, y, v) for v in range(1, size+1)] for y in range(size)] for x in range(size)\n",
    "        ]).reshape(-1, 3)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed, options=options)\n",
    "        self.board = np.zeros(self.size**2, dtype=np.int32)\n",
    "        return self.board, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        x, y, num = self.actions[action]\n",
    "\n",
    "        # 해당 위치에 숫자를 채우고 유효성을 검사\n",
    "        reward = 0\n",
    "        done = False\n",
    "        info = {}\n",
    "\n",
    "        # 유효성 검사\n",
    "        if self.is_valid_move(x, y, num):\n",
    "            self.board[x * 4 + y] = num\n",
    "            if self.is_game_over():\n",
    "                done = True\n",
    "                reward = 1  # 승리 보상\n",
    "            else:\n",
    "                reward = -10\n",
    "        else:\n",
    "            reward = -10  # 잘못된 행동에 대한 패널티\n",
    "\n",
    "        return self.board, reward, done, done, info\n",
    "\n",
    "    def is_valid_move(self, x, y, num):\n",
    "        # 행, 열, 2x2 블록에 중복된 숫자가 있는지 확인\n",
    "        # if self.board[x * self.size + y] != 0:\n",
    "        #     return False\n",
    "        \n",
    "        row_start = (x // self.half_size) * self.half_size\n",
    "        col_start = (y // self.half_size) * self.half_size\n",
    "        temp = self.board.reshape(self.size, self.size)\n",
    "\n",
    "        # print(num, row_start, col_start)\n",
    "        # print(self.board[x*self.size : (x+1)*self.size])\n",
    "        # print(self.board[y::self.size])\n",
    "        # print(temp)\n",
    "        # print(temp[row_start : row_start+self.half_size, col_start : col_start+self.half_size])\n",
    "        # print()\n",
    "\n",
    "        if (num in self.board[x*self.size : (x+1)*self.size]) or \\\n",
    "           (num in self.board[y::self.size]):\n",
    "            return False\n",
    "        if  (num in temp[row_start : row_start+self.half_size,\n",
    "                col_start : col_start+self.half_size]):\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def is_game_over(self):\n",
    "        # 게임이 종료되었는지 확인\n",
    "        return 0 not in self.board\n",
    "\n",
    "    def render(self):\n",
    "        # 현재 게임판 상태 출력\n",
    "        # print(np.array(self.board).reshape(self.size, self.size))\n",
    "        for i in range(self.size):\n",
    "            print(self.board[i*self.size:i*self.size+self.size])\n",
    "        print()\n",
    "\n",
    "# 환경 테스트\n",
    "env = SudokuEnv()\n",
    "observation = env.reset()\n",
    "env.render()\n",
    "done = False\n",
    "for i in range(400):\n",
    "    action = env.action_space.sample()  # 무작위 행동 선택\n",
    "    observation, reward, done, _, _ = env.step(action)\n",
    "    if i % 100 == 0:\n",
    "        env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "env = SudokuEnv()\n",
    "# If the environment don't follow the interface, an error will be thrown\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 362       |\n",
      "|    ep_rew_mean     | -3.34e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 769       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 2         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 1027      |\n",
      "|    iterations             | 2         |\n",
      "|    time_elapsed           | 3         |\n",
      "|    total_timesteps        | 4096      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -0.000883 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00265   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 1         |\n",
      "|    policy_objective       | 0.0371    |\n",
      "|    value_loss             | 2.04e+04  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 1153      |\n",
      "|    iterations             | 3         |\n",
      "|    time_elapsed           | 5         |\n",
      "|    total_timesteps        | 6144      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 6.69e-05  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00652   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 2         |\n",
      "|    policy_objective       | 0.035     |\n",
      "|    value_loss             | 2.17e+04  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 1230      |\n",
      "|    iterations             | 4         |\n",
      "|    time_elapsed           | 6         |\n",
      "|    total_timesteps        | 8192      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -1.57e-05 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00638   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 3         |\n",
      "|    policy_objective       | 0.0311    |\n",
      "|    value_loss             | 2.08e+04  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 1180      |\n",
      "|    iterations             | 5         |\n",
      "|    time_elapsed           | 8         |\n",
      "|    total_timesteps        | 10240     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 5.72e-06  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00679   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 4         |\n",
      "|    policy_objective       | 0.0353    |\n",
      "|    value_loss             | 1.93e+04  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 824       |\n",
      "|    iterations             | 6         |\n",
      "|    time_elapsed           | 14        |\n",
      "|    total_timesteps        | 12288     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 3.1e-06   |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00705   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 5         |\n",
      "|    policy_objective       | 0.0376    |\n",
      "|    value_loss             | 1.77e+04  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 790       |\n",
      "|    iterations             | 7         |\n",
      "|    time_elapsed           | 18        |\n",
      "|    total_timesteps        | 14336     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 5.01e-06  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00719   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 6         |\n",
      "|    policy_objective       | 0.0387    |\n",
      "|    value_loss             | 1.6e+04   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 842       |\n",
      "|    iterations             | 8         |\n",
      "|    time_elapsed           | 19        |\n",
      "|    total_timesteps        | 16384     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 1.79e-07  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00688   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 7         |\n",
      "|    policy_objective       | 0.0379    |\n",
      "|    value_loss             | 1.5e+04   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 792       |\n",
      "|    iterations             | 9         |\n",
      "|    time_elapsed           | 23        |\n",
      "|    total_timesteps        | 18432     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -3.22e-06 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00697   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 8         |\n",
      "|    policy_objective       | 0.0431    |\n",
      "|    value_loss             | 1.31e+04  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 826       |\n",
      "|    iterations             | 10        |\n",
      "|    time_elapsed           | 24        |\n",
      "|    total_timesteps        | 20480     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 2.98e-07  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00675   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 9         |\n",
      "|    policy_objective       | 0.0405    |\n",
      "|    value_loss             | 1.23e+04  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 860       |\n",
      "|    iterations             | 11        |\n",
      "|    time_elapsed           | 26        |\n",
      "|    total_timesteps        | 22528     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -8.34e-07 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00656   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 10        |\n",
      "|    policy_objective       | 0.0402    |\n",
      "|    value_loss             | 1.01e+04  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 890       |\n",
      "|    iterations             | 12        |\n",
      "|    time_elapsed           | 27        |\n",
      "|    total_timesteps        | 24576     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 5.36e-07  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00642   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 11        |\n",
      "|    policy_objective       | 0.0444    |\n",
      "|    value_loss             | 8.88e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 799       |\n",
      "|    iterations             | 13        |\n",
      "|    time_elapsed           | 33        |\n",
      "|    total_timesteps        | 26624     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -1.19e-07 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00663   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 12        |\n",
      "|    policy_objective       | 0.0444    |\n",
      "|    value_loss             | 7.33e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 764       |\n",
      "|    iterations             | 14        |\n",
      "|    time_elapsed           | 37        |\n",
      "|    total_timesteps        | 28672     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 5.96e-08  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00654   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 13        |\n",
      "|    policy_objective       | 0.0438    |\n",
      "|    value_loss             | 5.65e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 790       |\n",
      "|    iterations             | 15        |\n",
      "|    time_elapsed           | 38        |\n",
      "|    total_timesteps        | 30720     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -4.77e-07 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00702   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 14        |\n",
      "|    policy_objective       | 0.0456    |\n",
      "|    value_loss             | 4.09e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 762       |\n",
      "|    iterations             | 16        |\n",
      "|    time_elapsed           | 42        |\n",
      "|    total_timesteps        | 32768     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -3.58e-07 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00657   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 15        |\n",
      "|    policy_objective       | 0.0453    |\n",
      "|    value_loss             | 4.02e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 779       |\n",
      "|    iterations             | 17        |\n",
      "|    time_elapsed           | 44        |\n",
      "|    total_timesteps        | 34816     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -2.38e-07 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00635   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 16        |\n",
      "|    policy_objective       | 0.0444    |\n",
      "|    value_loss             | 2.49e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 798       |\n",
      "|    iterations             | 18        |\n",
      "|    time_elapsed           | 46        |\n",
      "|    total_timesteps        | 36864     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -2.38e-07 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00624   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 17        |\n",
      "|    policy_objective       | 0.0467    |\n",
      "|    value_loss             | 1.99e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 817       |\n",
      "|    iterations             | 19        |\n",
      "|    time_elapsed           | 47        |\n",
      "|    total_timesteps        | 38912     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -4.77e-07 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00679   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 18        |\n",
      "|    policy_objective       | 0.0451    |\n",
      "|    value_loss             | 1.27e+03  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 800       |\n",
      "|    iterations             | 20        |\n",
      "|    time_elapsed           | 51        |\n",
      "|    total_timesteps        | 40960     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 5.96e-08  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00635   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 19        |\n",
      "|    policy_objective       | 0.0445    |\n",
      "|    value_loss             | 750       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 804       |\n",
      "|    iterations             | 21        |\n",
      "|    time_elapsed           | 53        |\n",
      "|    total_timesteps        | 43008     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -2.38e-07 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00571   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 20        |\n",
      "|    policy_objective       | 0.0438    |\n",
      "|    value_loss             | 461       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 802       |\n",
      "|    iterations             | 22        |\n",
      "|    time_elapsed           | 56        |\n",
      "|    total_timesteps        | 45056     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -1.19e-07 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00561   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 21        |\n",
      "|    policy_objective       | 0.0421    |\n",
      "|    value_loss             | 252       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 800       |\n",
      "|    iterations             | 23        |\n",
      "|    time_elapsed           | 58        |\n",
      "|    total_timesteps        | 47104     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -2.38e-07 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00574   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 22        |\n",
      "|    policy_objective       | 0.0395    |\n",
      "|    value_loss             | 104       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 779       |\n",
      "|    iterations             | 24        |\n",
      "|    time_elapsed           | 63        |\n",
      "|    total_timesteps        | 49152     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -1.19e-07 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00535   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 23        |\n",
      "|    policy_objective       | 0.0411    |\n",
      "|    value_loss             | 103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 362       |\n",
      "|    ep_rew_mean            | -3.34e+03 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 794       |\n",
      "|    iterations             | 25        |\n",
      "|    time_elapsed           | 64        |\n",
      "|    total_timesteps        | 51200     |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | 5.96e-07  |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00546   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 24        |\n",
      "|    policy_objective       | 0.0399    |\n",
      "|    value_loss             | 123       |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# from stable_baselines3 import TRPO\n",
    "from sb3_contrib import TRPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "# from stable_baselines3.common.callbacks import EpsilonGreedyCallback\n",
    "\n",
    "# Instantiate the env\n",
    "vec_env = make_vec_env(SudokuEnv, n_envs=1, \n",
    "                       env_kwargs=dict(size=4))\n",
    "\n",
    "# Train the agent\n",
    "model = TRPO(\"MlpPolicy\", env, verbose=1).learn(50000)\n",
    "# 10000 -> 4\n",
    "# 100000 -> 48\n",
    "# 500000 -> 2440 (약 6분 소요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50 and action=19\n",
      "obs= [2 4 3 0 0 1 2 0 0 2 0 1 1 3 4 0] action= [1 0 4] reward= -10 done= False\n",
      "Step 100 and action=27\n",
      "obs= [2 4 3 0 0 1 2 0 4 2 0 1 1 3 4 0] action= [1 2 4] reward= -10 done= False\n",
      "Step 150 and action=23\n",
      "obs= [2 4 3 0 0 1 2 4 4 2 0 1 1 3 4 0] action= [1 1 4] reward= -10 done= False\n",
      "Step 200 and action=55\n",
      "obs= [2 4 3 0 3 1 2 4 4 2 0 1 1 3 4 0] action= [3 1 4] reward= -10 done= False\n",
      "Step 250 and action=45\n",
      "obs= [2 4 1 3 3 1 2 4 4 2 0 1 1 3 4 0] action= [2 3 2] reward= -10 done= False\n",
      "Goal reached! reward= 1 step= 295 obs= [2 4 1 3 3 1 2 4 4 2 3 1 1 3 4 2]\n"
     ]
    }
   ],
   "source": [
    "# Test the trained agent\n",
    "# using the vecenv\n",
    "obs = env.reset()[0]\n",
    "done = False\n",
    "step = 0\n",
    "while not done:\n",
    "    action, _ = model.predict(obs) #, deterministic=True)\n",
    "    step += 1\n",
    "    obs, reward, done, _, info = env.step(action)\n",
    "\n",
    "    if step % 50 == 0:\n",
    "        print(f\"Step {step} and action={action}\")\n",
    "        print(\"obs=\", obs, \"action=\", env.actions[action],\n",
    "              \"reward=\", reward, \"done=\", done)\n",
    "    if done:        \n",
    "        print(\"Goal reached!\", \"reward=\", reward, \"step=\", step, \"obs=\", obs)\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
